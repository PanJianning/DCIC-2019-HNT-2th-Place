{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "lgb.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# lightgbm的默认线程数是取openmp的默认线程数\n",
    "os.environ['NUM_OMP_THREADS'] = \"4\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from contextlib import contextmanager\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import warnings\n",
    "from scipy.stats import pearsonr\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from clf_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[load train_feat_df] done in 4.59 seconds\n",
      "[load test_feat_df] done in 6.83 seconds\n"
     ]
    }
   ],
   "source": [
    "with timer('load train_feat_df'):\n",
    "    train_feat_df = pd.read_csv('../input/train_feat_df.csv')\n",
    "with timer('load test_feat_df'):\n",
    "    test_feat_df = pd.read_csv('../input/test_feat_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feat_df = pd.concat([train_feat_df, pd.get_dummies(train_feat_df['设备类型'],prefix='设备类型')],axis=1)\n",
    "test_feat_df = pd.concat([test_feat_df, pd.get_dummies(test_feat_df['设备类型'],prefix='设备类型')],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_name1 = ['活塞工作时长','num_samples', '设备类型',\n",
    " 'min_发动机转速','max_发动机转速','nuni_发动机转速','mean_发动机转速',\n",
    " 'min_油泵转速','max_油泵转速','nuni_油泵转速','mean_油泵转速',\n",
    " 'min_泵送压力','max_泵送压力','nuni_泵送压力','mean_泵送压力',\n",
    " 'min_液压油温','max_液压油温','nuni_液压油温','mean_液压油温',\n",
    " 'min_流量档位','max_流量档位','nuni_流量档位','mean_流量档位',\n",
    " 'min_分配压力','max_分配压力','nuni_分配压力','mean_分配压力',\n",
    " 'min_排量电流','max_排量电流','nuni_排量电流','mean_排量电流',\n",
    " '低压开关','反泵']\n",
    "\n",
    "feature_name2 = ['活塞工作时长','num_samples',\n",
    " 'min_发动机转速','max_发动机转速','nuni_发动机转速','mean_发动机转速',\n",
    " 'min_油泵转速','max_油泵转速','nuni_油泵转速','mean_油泵转速',\n",
    " 'min_泵送压力','max_泵送压力','nuni_泵送压力','mean_泵送压力',\n",
    " 'min_液压油温','max_液压油温','nuni_液压油温','mean_液压油温',\n",
    " 'min_流量档位','max_流量档位','nuni_流量档位','mean_流量档位',\n",
    " 'min_分配压力','max_分配压力','nuni_分配压力','mean_分配压力',\n",
    " 'min_排量电流','max_排量电流','nuni_排量电流','mean_排量电流',\n",
    " '低压开关','正泵',\n",
    " '设备类型_0','设备类型_1','设备类型_2','设备类型_3','设备类型_4','设备类型_5','设备类型_6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================= Fold 1 =========================\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttrain's auc: 0.745392\ttrain's f1: 0.678138\ttest's auc: 0.694301\ttest's f1: 0.642197\n",
      "[400]\ttrain's auc: 0.79314\ttrain's f1: 0.715335\ttest's auc: 0.704095\ttest's f1: 0.649248\n",
      "[600]\ttrain's auc: 0.831638\ttrain's f1: 0.746322\ttest's auc: 0.711159\ttest's f1: 0.655829\n",
      "[800]\ttrain's auc: 0.861211\ttrain's f1: 0.772315\ttest's auc: 0.716164\ttest's f1: 0.659746\n",
      "Early stopping, best iteration is:\n",
      "[860]\ttrain's auc: 0.869011\ttrain's f1: 0.779974\ttest's auc: 0.718096\ttest's f1: 0.663272\n",
      "\n",
      "========================= Fold 2 =========================\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttrain's auc: 0.744784\ttrain's f1: 0.67947\ttest's auc: 0.691196\ttest's f1: 0.641727\n",
      "[400]\ttrain's auc: 0.789737\ttrain's f1: 0.712221\ttest's auc: 0.702113\ttest's f1: 0.649248\n",
      "[600]\ttrain's auc: 0.828455\ttrain's f1: 0.742758\ttest's auc: 0.710101\ttest's f1: 0.655437\n",
      "[800]\ttrain's auc: 0.859414\ttrain's f1: 0.769553\ttest's auc: 0.715621\ttest's f1: 0.657866\n",
      "[1000]\ttrain's auc: 0.883681\ttrain's f1: 0.792471\ttest's auc: 0.720446\ttest's f1: 0.660843\n",
      "[1200]\ttrain's auc: 0.903061\ttrain's f1: 0.811451\ttest's auc: 0.722194\ttest's f1: 0.66335\n",
      "[1400]\ttrain's auc: 0.918109\ttrain's f1: 0.829001\ttest's auc: 0.724815\ttest's f1: 0.66523\n",
      "[1600]\ttrain's auc: 0.929408\ttrain's f1: 0.843535\ttest's auc: 0.726728\ttest's f1: 0.665779\n",
      "Early stopping, best iteration is:\n",
      "[1506]\ttrain's auc: 0.924639\ttrain's f1: 0.837326\ttest's auc: 0.726332\ttest's f1: 0.666876\n",
      "\n",
      "========================= Fold 3 =========================\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttrain's auc: 0.744626\ttrain's f1: 0.678354\ttest's auc: 0.706639\ttest's f1: 0.650188\n",
      "[400]\ttrain's auc: 0.793171\ttrain's f1: 0.714552\ttest's auc: 0.71687\ttest's f1: 0.657396\n",
      "[600]\ttrain's auc: 0.830609\ttrain's f1: 0.744246\ttest's auc: 0.723383\ttest's f1: 0.665074\n",
      "[800]\ttrain's auc: 0.862593\ttrain's f1: 0.772746\ttest's auc: 0.7279\ttest's f1: 0.667737\n",
      "[1000]\ttrain's auc: 0.887526\ttrain's f1: 0.796878\ttest's auc: 0.731501\ttest's f1: 0.67142\n",
      "Early stopping, best iteration is:\n",
      "[964]\ttrain's auc: 0.883393\ttrain's f1: 0.793137\ttest's auc: 0.731184\ttest's f1: 0.672673\n",
      "\n",
      "========================= Fold 4 =========================\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttrain's auc: 0.74796\ttrain's f1: 0.682552\ttest's auc: 0.684766\ttest's f1: 0.636763\n",
      "[400]\ttrain's auc: 0.794273\ttrain's f1: 0.717006\ttest's auc: 0.695238\ttest's f1: 0.645851\n",
      "[600]\ttrain's auc: 0.830746\ttrain's f1: 0.746602\ttest's auc: 0.701516\ttest's f1: 0.649847\n",
      "[800]\ttrain's auc: 0.861599\ttrain's f1: 0.774396\ttest's auc: 0.707064\ttest's f1: 0.655253\n",
      "[1000]\ttrain's auc: 0.885246\ttrain's f1: 0.796177\ttest's auc: 0.710738\ttest's f1: 0.659328\n",
      "Early stopping, best iteration is:\n",
      "[1083]\ttrain's auc: 0.893651\ttrain's f1: 0.805285\ttest's auc: 0.712339\ttest's f1: 0.661992\n",
      "\n",
      "========================= Fold 5 =========================\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttrain's auc: 0.744617\ttrain's f1: 0.676212\ttest's auc: 0.697267\ttest's f1: 0.646685\n",
      "[400]\ttrain's auc: 0.790872\ttrain's f1: 0.711801\ttest's auc: 0.707002\ttest's f1: 0.652797\n",
      "[600]\ttrain's auc: 0.829684\ttrain's f1: 0.743649\ttest's auc: 0.713831\ttest's f1: 0.654443\n",
      "Early stopping, best iteration is:\n",
      "[526]\ttrain's auc: 0.816875\ttrain's f1: 0.732387\ttest's auc: 0.71236\ttest's f1: 0.656715\n",
      "0.6543554225363147\n"
     ]
    }
   ],
   "source": [
    "model = kf_lgbm(x=train_feat_df[feature_name1], y=train_feat_df.label.values, \n",
    "                x_test=test_feat_df[feature_name1], \n",
    "                output_dir='gotcha_lgb', name='lgb1',\n",
    "                random_state=1997,\n",
    "                n_folds=5, split_seed=8888,\n",
    "                learning_rate=0.03,\n",
    "                colsample_bytree=0.5,\n",
    "                early_stopping_rounds=100,\n",
    "                num_leaves=64, \n",
    "                min_split_gain=1,\n",
    "                n_estimators=5000,\n",
    "                eval_metric=metric_micro_f1,\n",
    "                max_depth=6)\n",
    "train_prob = np.load('./gotcha_lgb/val.lgb1.npy')\n",
    "test_prob = np.load('./gotcha_lgb/test.lgb1.npy')\n",
    "print(f1_score(train_feat_df.label.values,train_prob>0.46,average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================= Fold 1 =========================\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttrain's auc: 0.746354\ttrain's f1: 0.679647\ttest's auc: 0.684685\ttest's f1: 0.637496\n",
      "[400]\ttrain's auc: 0.794226\ttrain's f1: 0.717215\ttest's auc: 0.696679\ttest's f1: 0.648778\n",
      "[600]\ttrain's auc: 0.831604\ttrain's f1: 0.748203\ttest's auc: 0.704616\ttest's f1: 0.6534\n",
      "[800]\ttrain's auc: 0.863414\ttrain's f1: 0.775958\ttest's auc: 0.710284\ttest's f1: 0.656769\n",
      "[1000]\ttrain's auc: 0.887146\ttrain's f1: 0.798366\ttest's auc: 0.713764\ttest's f1: 0.658101\n",
      "Early stopping, best iteration is:\n",
      "[1022]\ttrain's auc: 0.889859\ttrain's f1: 0.800854\ttest's auc: 0.714197\ttest's f1: 0.659825\n",
      "\n",
      "========================= Fold 2 =========================\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttrain's auc: 0.742059\ttrain's f1: 0.674671\ttest's auc: 0.69334\ttest's f1: 0.638671\n",
      "[400]\ttrain's auc: 0.790368\ttrain's f1: 0.71085\ttest's auc: 0.704081\ttest's f1: 0.649013\n",
      "[600]\ttrain's auc: 0.829436\ttrain's f1: 0.741602\ttest's auc: 0.712513\ttest's f1: 0.655594\n",
      "[800]\ttrain's auc: 0.860639\ttrain's f1: 0.770278\ttest's auc: 0.717428\ttest's f1: 0.661861\n",
      "[1000]\ttrain's auc: 0.886636\ttrain's f1: 0.795781\ttest's auc: 0.721447\ttest's f1: 0.666484\n",
      "Early stopping, best iteration is:\n",
      "[959]\ttrain's auc: 0.882577\ttrain's f1: 0.791785\ttest's auc: 0.72083\ttest's f1: 0.667189\n",
      "\n",
      "========================= Fold 3 =========================\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttrain's auc: 0.744668\ttrain's f1: 0.677218\ttest's auc: 0.698126\ttest's f1: 0.640552\n",
      "[400]\ttrain's auc: 0.791963\ttrain's f1: 0.712123\ttest's auc: 0.708906\ttest's f1: 0.653635\n",
      "[600]\ttrain's auc: 0.830454\ttrain's f1: 0.744422\ttest's auc: 0.714528\ttest's f1: 0.658023\n",
      "[800]\ttrain's auc: 0.860012\ttrain's f1: 0.770885\ttest's auc: 0.717759\ttest's f1: 0.66147\n",
      "Early stopping, best iteration is:\n",
      "[817]\ttrain's auc: 0.862253\ttrain's f1: 0.772844\ttest's auc: 0.718249\ttest's f1: 0.663428\n",
      "\n",
      "========================= Fold 4 =========================\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttrain's auc: 0.741909\ttrain's f1: 0.675735\ttest's auc: 0.696289\ttest's f1: 0.644206\n",
      "[400]\ttrain's auc: 0.791125\ttrain's f1: 0.71301\ttest's auc: 0.706717\ttest's f1: 0.651571\n",
      "[600]\ttrain's auc: 0.831016\ttrain's f1: 0.745191\ttest's auc: 0.713156\ttest's f1: 0.65588\n",
      "[800]\ttrain's auc: 0.86251\ttrain's f1: 0.772692\ttest's auc: 0.717545\ttest's f1: 0.660033\n",
      "[1000]\ttrain's auc: 0.886564\ttrain's f1: 0.795628\ttest's auc: 0.720971\ttest's f1: 0.66207\n",
      "Early stopping, best iteration is:\n",
      "[902]\ttrain's auc: 0.876195\ttrain's f1: 0.78558\ttest's auc: 0.719329\ttest's f1: 0.663245\n",
      "\n",
      "========================= Fold 5 =========================\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttrain's auc: 0.748421\ttrain's f1: 0.681853\ttest's auc: 0.69624\ttest's f1: 0.641122\n",
      "[400]\ttrain's auc: 0.795638\ttrain's f1: 0.715718\ttest's auc: 0.704275\ttest's f1: 0.647939\n",
      "[600]\ttrain's auc: 0.83351\ttrain's f1: 0.747468\ttest's auc: 0.711066\ttest's f1: 0.652641\n",
      "[800]\ttrain's auc: 0.863415\ttrain's f1: 0.775027\ttest's auc: 0.71621\ttest's f1: 0.660476\n",
      "[1000]\ttrain's auc: 0.886482\ttrain's f1: 0.797375\ttest's auc: 0.720387\ttest's f1: 0.663454\n",
      "[1200]\ttrain's auc: 0.905786\ttrain's f1: 0.816081\ttest's auc: 0.723268\ttest's f1: 0.665648\n",
      "Early stopping, best iteration is:\n",
      "[1211]\ttrain's auc: 0.9066\ttrain's f1: 0.817393\ttest's auc: 0.723374\ttest's f1: 0.666667\n",
      "0.6540420264192927\n"
     ]
    }
   ],
   "source": [
    "model = kf_lgbm(x=train_feat_df[feature_name1], y=train_feat_df.label.values, \n",
    "                x_test=test_feat_df[feature_name1], \n",
    "                output_dir='gotcha_lgb', name='lgb2',\n",
    "                random_state=2019,\n",
    "                n_folds=5, split_seed=2333,\n",
    "                learning_rate=0.03,\n",
    "                colsample_bytree=0.5,\n",
    "                early_stopping_rounds=100,\n",
    "                num_leaves=64, \n",
    "                min_split_gain=1,\n",
    "                n_estimators=5000,\n",
    "                eval_metric=metric_micro_f1,\n",
    "                max_depth=6)\n",
    "train_prob = np.load('./gotcha_lgb/val.lgb2.npy')\n",
    "test_prob = np.load('./gotcha_lgb/test.lgb2.npy')\n",
    "print(f1_score(train_feat_df.label.values,train_prob>0.46,average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================= Fold 1 =========================\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttrain's auc: 0.744623\ttrain's f1: 0.678178\ttest's auc: 0.692209\ttest's f1: 0.637026\n",
      "[400]\ttrain's auc: 0.791276\ttrain's f1: 0.713984\ttest's auc: 0.70194\ttest's f1: 0.645722\n",
      "[600]\ttrain's auc: 0.830227\ttrain's f1: 0.743756\ttest's auc: 0.709311\ttest's f1: 0.651598\n",
      "[800]\ttrain's auc: 0.859727\ttrain's f1: 0.769573\ttest's auc: 0.714142\ttest's f1: 0.657004\n",
      "[1000]\ttrain's auc: 0.885703\ttrain's f1: 0.79441\ttest's auc: 0.719602\ttest's f1: 0.661861\n",
      "Early stopping, best iteration is:\n",
      "[1030]\ttrain's auc: 0.888515\ttrain's f1: 0.797485\ttest's auc: 0.719782\ttest's f1: 0.662175\n",
      "\n",
      "========================= Fold 2 =========================\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttrain's auc: 0.743329\ttrain's f1: 0.676591\ttest's auc: 0.703211\ttest's f1: 0.650893\n",
      "[400]\ttrain's auc: 0.793137\ttrain's f1: 0.71508\ttest's auc: 0.71319\ttest's f1: 0.657004\n",
      "[600]\ttrain's auc: 0.830945\ttrain's f1: 0.745363\ttest's auc: 0.720754\ttest's f1: 0.664917\n",
      "Early stopping, best iteration is:\n",
      "[583]\ttrain's auc: 0.827748\ttrain's f1: 0.741935\ttest's auc: 0.719955\ttest's f1: 0.667816\n",
      "\n",
      "========================= Fold 3 =========================\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttrain's auc: 0.745381\ttrain's f1: 0.679882\ttest's auc: 0.69311\ttest's f1: 0.642902\n",
      "[400]\ttrain's auc: 0.79353\ttrain's f1: 0.715413\ttest's auc: 0.702476\ttest's f1: 0.64917\n",
      "[600]\ttrain's auc: 0.830401\ttrain's f1: 0.745088\ttest's auc: 0.708935\ttest's f1: 0.654654\n",
      "Early stopping, best iteration is:\n",
      "[662]\ttrain's auc: 0.840274\ttrain's f1: 0.752923\ttest's auc: 0.71062\ttest's f1: 0.656926\n",
      "\n",
      "========================= Fold 4 =========================\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttrain's auc: 0.745255\ttrain's f1: 0.678674\ttest's auc: 0.696298\ttest's f1: 0.648672\n",
      "[400]\ttrain's auc: 0.792909\ttrain's f1: 0.715145\ttest's auc: 0.706147\ttest's f1: 0.653608\n",
      "[600]\ttrain's auc: 0.832923\ttrain's f1: 0.747522\ttest's auc: 0.713876\ttest's f1: 0.662462\n",
      "[800]\ttrain's auc: 0.86421\ttrain's f1: 0.775747\ttest's auc: 0.718413\ttest's f1: 0.663872\n",
      "[1000]\ttrain's auc: 0.888864\ttrain's f1: 0.799526\ttest's auc: 0.72312\ttest's f1: 0.67014\n",
      "Early stopping, best iteration is:\n",
      "[1026]\ttrain's auc: 0.891579\ttrain's f1: 0.801896\ttest's auc: 0.723516\ttest's f1: 0.671316\n",
      "\n",
      "========================= Fold 5 =========================\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttrain's auc: 0.746872\ttrain's f1: 0.679659\ttest's auc: 0.688226\ttest's f1: 0.636186\n",
      "[400]\ttrain's auc: 0.794107\ttrain's f1: 0.715092\ttest's auc: 0.698323\ttest's f1: 0.644021\n",
      "[600]\ttrain's auc: 0.830267\ttrain's f1: 0.744805\ttest's auc: 0.70435\ttest's f1: 0.649898\n",
      "[800]\ttrain's auc: 0.861035\ttrain's f1: 0.769797\ttest's auc: 0.710072\ttest's f1: 0.654129\n",
      "[1000]\ttrain's auc: 0.886217\ttrain's f1: 0.794555\ttest's auc: 0.715048\ttest's f1: 0.656637\n",
      "[1200]\ttrain's auc: 0.904782\ttrain's f1: 0.814377\ttest's auc: 0.717973\ttest's f1: 0.660241\n",
      "[1400]\ttrain's auc: 0.919229\ttrain's f1: 0.830457\ttest's auc: 0.719512\ttest's f1: 0.661573\n",
      "[1600]\ttrain's auc: 0.93033\ttrain's f1: 0.844344\ttest's auc: 0.721171\ttest's f1: 0.664708\n",
      "[1800]\ttrain's auc: 0.939222\ttrain's f1: 0.855411\ttest's auc: 0.72211\ttest's f1: 0.665491\n",
      "Early stopping, best iteration is:\n",
      "[1754]\ttrain's auc: 0.937579\ttrain's f1: 0.852923\ttest's auc: 0.722088\ttest's f1: 0.666353\n",
      "0.6533368851559929\n"
     ]
    }
   ],
   "source": [
    "model = kf_lgbm(x=train_feat_df[feature_name1], y=train_feat_df.label.values, \n",
    "                x_test=test_feat_df[feature_name1], \n",
    "                output_dir='gotcha_lgb', name='lgb3',\n",
    "                random_state=2012,\n",
    "                n_folds=5, split_seed=6666,\n",
    "                learning_rate=0.03,\n",
    "                colsample_bytree=0.5,\n",
    "                early_stopping_rounds=100,\n",
    "                num_leaves=64, \n",
    "                min_split_gain=1,\n",
    "                n_estimators=5000,\n",
    "                eval_metric=metric_micro_f1,\n",
    "                max_depth=6)\n",
    "train_prob = np.load('./gotcha_lgb/val.lgb3.npy')\n",
    "test_prob = np.load('./gotcha_lgb/test.lgb3.npy')\n",
    "print(f1_score(train_feat_df.label.values,train_prob>0.46,average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================= Fold 1 =========================\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttrain's auc: 0.687872\ttrain's f1: 0.636633\ttest's auc: 0.670254\ttest's f1: 0.622924\n",
      "[400]\ttrain's auc: 0.710225\ttrain's f1: 0.654908\ttest's auc: 0.679718\ttest's f1: 0.633814\n",
      "[600]\ttrain's auc: 0.727835\ttrain's f1: 0.66668\ttest's auc: 0.685206\ttest's f1: 0.640081\n",
      "[800]\ttrain's auc: 0.743572\ttrain's f1: 0.678883\ttest's auc: 0.689342\ttest's f1: 0.642824\n",
      "[1000]\ttrain's auc: 0.758556\ttrain's f1: 0.689068\ttest's auc: 0.692878\ttest's f1: 0.643764\n",
      "[1200]\ttrain's auc: 0.772003\ttrain's f1: 0.699665\ttest's auc: 0.69567\ttest's f1: 0.647446\n",
      "Early stopping, best iteration is:\n",
      "[1178]\ttrain's auc: 0.770787\ttrain's f1: 0.698627\ttest's auc: 0.695372\ttest's f1: 0.648073\n",
      "\n",
      "========================= Fold 2 =========================\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttrain's auc: 0.689531\ttrain's f1: 0.635888\ttest's auc: 0.670475\ttest's f1: 0.618066\n",
      "[400]\ttrain's auc: 0.711953\ttrain's f1: 0.652929\ttest's auc: 0.677346\ttest's f1: 0.624412\n",
      "[600]\ttrain's auc: 0.730255\ttrain's f1: 0.666151\ttest's auc: 0.682113\ttest's f1: 0.62927\n",
      "[800]\ttrain's auc: 0.7456\ttrain's f1: 0.677786\ttest's auc: 0.686005\ttest's f1: 0.634832\n",
      "Early stopping, best iteration is:\n",
      "[819]\ttrain's auc: 0.747055\ttrain's f1: 0.678413\ttest's auc: 0.686171\ttest's f1: 0.635929\n",
      "\n",
      "========================= Fold 3 =========================\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttrain's auc: 0.688668\ttrain's f1: 0.633675\ttest's auc: 0.669644\ttest's f1: 0.620965\n",
      "[400]\ttrain's auc: 0.711051\ttrain's f1: 0.652146\ttest's auc: 0.678744\ttest's f1: 0.630602\n",
      "[600]\ttrain's auc: 0.728957\ttrain's f1: 0.667111\ttest's auc: 0.684022\ttest's f1: 0.633265\n",
      "[800]\ttrain's auc: 0.74472\ttrain's f1: 0.680058\ttest's auc: 0.687843\ttest's f1: 0.637104\n",
      "[1000]\ttrain's auc: 0.759053\ttrain's f1: 0.69087\ttest's auc: 0.691425\ttest's f1: 0.64063\n",
      "Early stopping, best iteration is:\n",
      "[931]\ttrain's auc: 0.754289\ttrain's f1: 0.687364\ttest's auc: 0.69064\ttest's f1: 0.641492\n",
      "\n",
      "========================= Fold 4 =========================\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttrain's auc: 0.687267\ttrain's f1: 0.633878\ttest's auc: 0.675005\ttest's f1: 0.627595\n",
      "[400]\ttrain's auc: 0.708706\ttrain's f1: 0.649841\ttest's auc: 0.68275\ttest's f1: 0.63261\n",
      "[600]\ttrain's auc: 0.726682\ttrain's f1: 0.66269\ttest's auc: 0.687742\ttest's f1: 0.635431\n",
      "[800]\ttrain's auc: 0.74223\ttrain's f1: 0.674854\ttest's auc: 0.692623\ttest's f1: 0.638956\n",
      "[1000]\ttrain's auc: 0.756665\ttrain's f1: 0.685803\ttest's auc: 0.696128\ttest's f1: 0.641542\n",
      "Early stopping, best iteration is:\n",
      "[933]\ttrain's auc: 0.751883\ttrain's f1: 0.68214\ttest's auc: 0.694883\ttest's f1: 0.643266\n",
      "\n",
      "========================= Fold 5 =========================\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttrain's auc: 0.68662\ttrain's f1: 0.633337\ttest's auc: 0.674593\ttest's f1: 0.624197\n",
      "[400]\ttrain's auc: 0.707852\ttrain's f1: 0.648223\ttest's auc: 0.683878\ttest's f1: 0.634227\n",
      "[600]\ttrain's auc: 0.726056\ttrain's f1: 0.662031\ttest's auc: 0.690591\ttest's f1: 0.641514\n",
      "[800]\ttrain's auc: 0.742272\ttrain's f1: 0.673548\ttest's auc: 0.695211\ttest's f1: 0.646294\n",
      "Early stopping, best iteration is:\n",
      "[839]\ttrain's auc: 0.745606\ttrain's f1: 0.676369\ttest's auc: 0.695831\ttest's f1: 0.648253\n",
      "0.6321042982277449\n"
     ]
    }
   ],
   "source": [
    "model = kf_lgbm(x=train_feat_df[feature_name1], y=train_feat_df.label.values, \n",
    "                x_test=test_feat_df[feature_name1], \n",
    "                output_dir='gotcha_lgb', name='lgb4',\n",
    "                random_state=1234,\n",
    "                min_child_samples=50,\n",
    "                n_folds=5, split_seed=4321,\n",
    "                learning_rate=0.03,\n",
    "                colsample_bytree=0.5,\n",
    "                early_stopping_rounds=100,\n",
    "                num_leaves=64, \n",
    "                min_split_gain=0.9,\n",
    "                n_estimators=5000,\n",
    "                eval_metric=metric_micro_f1,\n",
    "                max_depth=4)\n",
    "train_prob = np.load('./gotcha_lgb/val.lgb4.npy')\n",
    "test_prob = np.load('./gotcha_lgb/test.lgb4.npy')\n",
    "print(f1_score(train_feat_df.label.values,train_prob>0.46,average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================= Fold 1 =========================\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttrain's auc: 0.688982\ttrain's f1: 0.636006\ttest's auc: 0.667462\ttest's f1: 0.617361\n",
      "[400]\ttrain's auc: 0.710064\ttrain's f1: 0.651597\ttest's auc: 0.676461\ttest's f1: 0.626371\n",
      "[600]\ttrain's auc: 0.727986\ttrain's f1: 0.664662\ttest's auc: 0.682081\ttest's f1: 0.631542\n",
      "[800]\ttrain's auc: 0.743291\ttrain's f1: 0.675239\ttest's auc: 0.68611\ttest's f1: 0.633579\n",
      "[1000]\ttrain's auc: 0.758009\ttrain's f1: 0.686914\ttest's auc: 0.690574\ttest's f1: 0.636713\n",
      "[1200]\ttrain's auc: 0.770569\ttrain's f1: 0.697158\ttest's auc: 0.692541\ttest's f1: 0.640865\n",
      "Early stopping, best iteration is:\n",
      "[1242]\ttrain's auc: 0.77325\ttrain's f1: 0.698784\ttest's auc: 0.692991\ttest's f1: 0.642118\n",
      "\n",
      "========================= Fold 2 =========================\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttrain's auc: 0.687015\ttrain's f1: 0.633009\ttest's auc: 0.675821\ttest's f1: 0.62739\n",
      "[400]\ttrain's auc: 0.7097\ttrain's f1: 0.650971\ttest's auc: 0.684279\ttest's f1: 0.634362\n",
      "[600]\ttrain's auc: 0.728535\ttrain's f1: 0.665818\ttest's auc: 0.689782\ttest's f1: 0.638358\n",
      "[800]\ttrain's auc: 0.744691\ttrain's f1: 0.677159\ttest's auc: 0.693375\ttest's f1: 0.642824\n",
      "[1000]\ttrain's auc: 0.758288\ttrain's f1: 0.687286\ttest's auc: 0.696069\ttest's f1: 0.644704\n",
      "[1200]\ttrain's auc: 0.771191\ttrain's f1: 0.697315\ttest's auc: 0.698153\ttest's f1: 0.647133\n",
      "Early stopping, best iteration is:\n",
      "[1192]\ttrain's auc: 0.770561\ttrain's f1: 0.697138\ttest's auc: 0.698123\ttest's f1: 0.647603\n",
      "\n",
      "========================= Fold 3 =========================\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttrain's auc: 0.687032\ttrain's f1: 0.633596\ttest's auc: 0.671243\ttest's f1: 0.622219\n",
      "[400]\ttrain's auc: 0.708476\ttrain's f1: 0.650167\ttest's auc: 0.68003\ttest's f1: 0.630288\n",
      "[600]\ttrain's auc: 0.725993\ttrain's f1: 0.662743\ttest's auc: 0.68519\ttest's f1: 0.633187\n",
      "Early stopping, best iteration is:\n",
      "[683]\ttrain's auc: 0.73272\ttrain's f1: 0.666993\ttest's auc: 0.687318\ttest's f1: 0.635537\n",
      "\n",
      "========================= Fold 4 =========================\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttrain's auc: 0.68849\ttrain's f1: 0.634642\ttest's auc: 0.672173\ttest's f1: 0.622189\n",
      "[400]\ttrain's auc: 0.709651\ttrain's f1: 0.650272\ttest's auc: 0.6803\ttest's f1: 0.627909\n",
      "[600]\ttrain's auc: 0.727509\ttrain's f1: 0.662847\ttest's auc: 0.685635\ttest's f1: 0.634725\n",
      "[800]\ttrain's auc: 0.74338\ttrain's f1: 0.675285\ttest's auc: 0.690432\ttest's f1: 0.641229\n",
      "Early stopping, best iteration is:\n",
      "[768]\ttrain's auc: 0.740995\ttrain's f1: 0.674012\ttest's auc: 0.689658\ttest's f1: 0.642404\n",
      "\n",
      "========================= Fold 5 =========================\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttrain's auc: 0.688011\ttrain's f1: 0.63555\ttest's auc: 0.671297\ttest's f1: 0.62263\n",
      "[400]\ttrain's auc: 0.709239\ttrain's f1: 0.651239\ttest's auc: 0.679009\ttest's f1: 0.632189\n",
      "[600]\ttrain's auc: 0.72727\ttrain's f1: 0.664577\ttest's auc: 0.683903\ttest's f1: 0.635089\n",
      "[800]\ttrain's auc: 0.742662\ttrain's f1: 0.676094\ttest's auc: 0.688066\ttest's f1: 0.637674\n",
      "[1000]\ttrain's auc: 0.756993\ttrain's f1: 0.687553\ttest's auc: 0.691144\ttest's f1: 0.642141\n",
      "[1200]\ttrain's auc: 0.7694\ttrain's f1: 0.696817\ttest's auc: 0.694246\ttest's f1: 0.642846\n",
      "Early stopping, best iteration is:\n",
      "[1268]\ttrain's auc: 0.773538\ttrain's f1: 0.70001\ttest's auc: 0.695272\ttest's f1: 0.645118\n",
      "0.6322296566745538\n"
     ]
    }
   ],
   "source": [
    "model = kf_lgbm(x=train_feat_df[feature_name1], y=train_feat_df.label.values, \n",
    "                x_test=test_feat_df[feature_name1], \n",
    "                output_dir='gotcha_lgb', name='lgb5',\n",
    "                random_state=987,\n",
    "                min_child_samples=50,\n",
    "                n_folds=5, split_seed=789,\n",
    "                learning_rate=0.03,\n",
    "                colsample_bytree=0.5,\n",
    "                early_stopping_rounds=100,\n",
    "                num_leaves=64, \n",
    "                min_split_gain=0.9,\n",
    "                n_estimators=5000,\n",
    "                eval_metric=metric_micro_f1,\n",
    "                max_depth=4)\n",
    "train_prob = np.load('./gotcha_lgb/val.lgb5.npy')\n",
    "test_prob = np.load('./gotcha_lgb/test.lgb5.npy')\n",
    "print(f1_score(train_feat_df.label.values,train_prob>0.46,average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================= Fold 1 =========================\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttrain's auc: 0.689101\ttrain's f1: 0.635066\ttest's auc: 0.666519\ttest's f1: 0.619477\n",
      "[400]\ttrain's auc: 0.710989\ttrain's f1: 0.652459\ttest's auc: 0.676031\ttest's f1: 0.62739\n",
      "[600]\ttrain's auc: 0.728115\ttrain's f1: 0.664721\ttest's auc: 0.681135\ttest's f1: 0.63303\n",
      "[800]\ttrain's auc: 0.743569\ttrain's f1: 0.67663\ttest's auc: 0.685494\ttest's f1: 0.636243\n",
      "Early stopping, best iteration is:\n",
      "[781]\ttrain's auc: 0.74221\ttrain's f1: 0.675533\ttest's auc: 0.685355\ttest's f1: 0.637339\n",
      "\n",
      "========================= Fold 2 =========================\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttrain's auc: 0.686506\ttrain's f1: 0.633616\ttest's auc: 0.67416\ttest's f1: 0.625823\n",
      "[400]\ttrain's auc: 0.707825\ttrain's f1: 0.648346\ttest's auc: 0.681764\ttest's f1: 0.631855\n",
      "[600]\ttrain's auc: 0.725883\ttrain's f1: 0.661783\ttest's auc: 0.686547\ttest's f1: 0.637496\n",
      "Early stopping, best iteration is:\n",
      "[617]\ttrain's auc: 0.727114\ttrain's f1: 0.662723\ttest's auc: 0.686825\ttest's f1: 0.63875\n",
      "\n",
      "========================= Fold 3 =========================\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttrain's auc: 0.689966\ttrain's f1: 0.636633\ttest's auc: 0.665924\ttest's f1: 0.623551\n",
      "[400]\ttrain's auc: 0.711749\ttrain's f1: 0.65338\ttest's auc: 0.674401\ttest's f1: 0.630523\n",
      "[600]\ttrain's auc: 0.728894\ttrain's f1: 0.666131\ttest's auc: 0.67865\ttest's f1: 0.630915\n",
      "[800]\ttrain's auc: 0.745107\ttrain's f1: 0.677766\ttest's auc: 0.68259\ttest's f1: 0.634127\n",
      "[1000]\ttrain's auc: 0.758743\ttrain's f1: 0.688637\ttest's auc: 0.686248\ttest's f1: 0.636634\n",
      "[1200]\ttrain's auc: 0.772037\ttrain's f1: 0.699117\ttest's auc: 0.689607\ttest's f1: 0.641413\n",
      "Early stopping, best iteration is:\n",
      "[1188]\ttrain's auc: 0.771278\ttrain's f1: 0.698686\ttest's auc: 0.689404\ttest's f1: 0.642353\n",
      "\n",
      "========================= Fold 4 =========================\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttrain's auc: 0.68766\ttrain's f1: 0.636307\ttest's auc: 0.680434\ttest's f1: 0.631513\n",
      "[400]\ttrain's auc: 0.708982\ttrain's f1: 0.650742\ttest's auc: 0.687369\ttest's f1: 0.639113\n",
      "[600]\ttrain's auc: 0.726784\ttrain's f1: 0.663591\ttest's auc: 0.692208\ttest's f1: 0.644363\n",
      "[800]\ttrain's auc: 0.742438\ttrain's f1: 0.675305\ttest's auc: 0.695316\ttest's f1: 0.64546\n",
      "[1000]\ttrain's auc: 0.756829\ttrain's f1: 0.68594\ttest's auc: 0.698216\ttest's f1: 0.647105\n",
      "[1200]\ttrain's auc: 0.770202\ttrain's f1: 0.696126\ttest's auc: 0.700586\ttest's f1: 0.649847\n",
      "Early stopping, best iteration is:\n",
      "[1226]\ttrain's auc: 0.771567\ttrain's f1: 0.69687\ttest's auc: 0.70083\ttest's f1: 0.650317\n",
      "\n",
      "========================= Fold 5 =========================\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttrain's auc: 0.687579\ttrain's f1: 0.632886\ttest's auc: 0.669853\ttest's f1: 0.621689\n",
      "[400]\ttrain's auc: 0.709886\ttrain's f1: 0.648477\ttest's auc: 0.679364\ttest's f1: 0.631249\n",
      "[600]\ttrain's auc: 0.728257\ttrain's f1: 0.663402\ttest's auc: 0.684699\ttest's f1: 0.636264\n",
      "[800]\ttrain's auc: 0.744452\ttrain's f1: 0.675624\ttest's auc: 0.689105\ttest's f1: 0.640887\n",
      "Early stopping, best iteration is:\n",
      "[882]\ttrain's auc: 0.750769\ttrain's f1: 0.679894\ttest's auc: 0.690436\ttest's f1: 0.642689\n",
      "0.6315871946346585\n"
     ]
    }
   ],
   "source": [
    "model = kf_lgbm(x=train_feat_df[feature_name1], y=train_feat_df.label.values, \n",
    "                x_test=test_feat_df[feature_name1], \n",
    "                output_dir='gotcha_lgb', name='lgb6',\n",
    "                random_state=2015,\n",
    "                min_child_samples=50,\n",
    "                n_folds=5, split_seed=2012,\n",
    "                learning_rate=0.03,\n",
    "                colsample_bytree=0.5,\n",
    "                early_stopping_rounds=100,\n",
    "                num_leaves=64, \n",
    "                min_split_gain=0.9,\n",
    "                n_estimators=5000,\n",
    "                eval_metric=metric_micro_f1,\n",
    "                max_depth=4)\n",
    "train_prob = np.load('./gotcha_lgb/val.lgb6.npy')\n",
    "test_prob = np.load('./gotcha_lgb/test.lgb6.npy')\n",
    "print(f1_score(train_feat_df.label.values,train_prob>0.46,average='micro'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
